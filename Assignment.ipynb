{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmRbPqCoV8hW"
      },
      "source": [
        "# <span style=\"color:blue\">Quant Final Project</span>\n",
        "## Finance 372 - Prof Travis Johnson"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rY2TsKH4V8hY"
      },
      "source": [
        "## Solution by: <span style=\"color:orange\">Trent Becker, Arjun Nair, Madhavan Uchani </span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RXYIbw3rV8hY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WpnDfGn0V8hZ"
      },
      "outputs": [],
      "source": [
        "# Solution\n",
        "# signal_df = pd.read_stata(\"final_project_data.dta\")\n",
        "#TODO --> Determine if we need the foreign identifier code from compustat data or if we can justify not needing it\n",
        "df = pd.read_csv(\"crsp_finalproject.csv\", dtype={'PERMNO': 'str', 'date': 'str', 'TICKER': 'str', 'COMNAM': 'str', 'PRC': 'float', 'VOL': 'float', 'RET': 'str', 'SHROUT': 'float'})\n",
        "df['RET'] = pd.to_numeric(df['RET'], errors='coerce')\n",
        "df['RET'] = df['RET'].astype(float)\n",
        "df = df[df['date'] >= '1983-06-01']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x8huJPhV8hZ"
      },
      "source": [
        "Now remove unnecessary columns, keeping only gvkey, datadate, at, cogs, and revt. Write the edited dataframe into a .dta file using `.to_stata('gp_data.dta',write_index=False)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_A8xzlAV8hZ"
      },
      "outputs": [],
      "source": [
        "# Solution\n",
        "#signal_df = signal_df[['PERMNO', 'date', 'TICKER', 'COMNAM', 'PRC', 'VOL', 'RET', 'SHROUT']]\n",
        "#signal_df.to_stata('index_rebalancing_data.dta', write_index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJKZFr4rV8ha"
      },
      "source": [
        "Run this cell without editing it to show us what your signal_df looks like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "wlFy9pWHV8ha",
        "outputId": "e4480a66-9356-4997-a5a0-5052cca747fc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PERMNO</th>\n",
              "      <th>date</th>\n",
              "      <th>TICKER</th>\n",
              "      <th>COMNAM</th>\n",
              "      <th>PRC</th>\n",
              "      <th>VOL</th>\n",
              "      <th>RET</th>\n",
              "      <th>SHROUT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1079</th>\n",
              "      <td>10006</td>\n",
              "      <td>1984-04-30</td>\n",
              "      <td>ACF</td>\n",
              "      <td>A C F INDUSTRIES INC</td>\n",
              "      <td>52.6250</td>\n",
              "      <td>19428.0</td>\n",
              "      <td>0.031863</td>\n",
              "      <td>8385.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1936</th>\n",
              "      <td>10015</td>\n",
              "      <td>1984-04-30</td>\n",
              "      <td>AMFD</td>\n",
              "      <td>A &amp; M FOOD SERVICES INC</td>\n",
              "      <td>-7.2500</td>\n",
              "      <td>1362.0</td>\n",
              "      <td>0.104762</td>\n",
              "      <td>3568.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4175</th>\n",
              "      <td>10031</td>\n",
              "      <td>1984-04-30</td>\n",
              "      <td>ANTQ</td>\n",
              "      <td>A A IMPORTING INC</td>\n",
              "      <td>-4.3125</td>\n",
              "      <td>203.0</td>\n",
              "      <td>-0.178571</td>\n",
              "      <td>2683.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8015</th>\n",
              "      <td>10057</td>\n",
              "      <td>1984-04-30</td>\n",
              "      <td>AMT</td>\n",
              "      <td>ACME CLEVELAND CORP</td>\n",
              "      <td>21.0000</td>\n",
              "      <td>2576.0</td>\n",
              "      <td>0.004762</td>\n",
              "      <td>6106.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8300</th>\n",
              "      <td>10058</td>\n",
              "      <td>1984-04-30</td>\n",
              "      <td>ABKC</td>\n",
              "      <td>A B K C O INDUSTRIES INC</td>\n",
              "      <td>-0.6875</td>\n",
              "      <td>6.0</td>\n",
              "      <td>-0.083333</td>\n",
              "      <td>1089.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4018028</th>\n",
              "      <td>90705</td>\n",
              "      <td>1984-04-30</td>\n",
              "      <td>OPTC</td>\n",
              "      <td>OPTELECOM INC</td>\n",
              "      <td>-4.6875</td>\n",
              "      <td>1318.0</td>\n",
              "      <td>-0.157303</td>\n",
              "      <td>3025.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4051671</th>\n",
              "      <td>90975</td>\n",
              "      <td>1984-04-30</td>\n",
              "      <td>PEOP</td>\n",
              "      <td>PEOPLES BAN CORP</td>\n",
              "      <td>-25.2500</td>\n",
              "      <td>834.0</td>\n",
              "      <td>0.052083</td>\n",
              "      <td>3782.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4206531</th>\n",
              "      <td>92321</td>\n",
              "      <td>1984-04-30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>TAURUS OIL CORP</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15639.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4274787</th>\n",
              "      <td>92946</td>\n",
              "      <td>1984-04-30</td>\n",
              "      <td>VYQT</td>\n",
              "      <td>VYQUEST INC</td>\n",
              "      <td>-5.3125</td>\n",
              "      <td>360.0</td>\n",
              "      <td>-0.086022</td>\n",
              "      <td>3837.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4298584</th>\n",
              "      <td>93172</td>\n",
              "      <td>1984-04-30</td>\n",
              "      <td>WINNS</td>\n",
              "      <td>WINN ENTERPRISES</td>\n",
              "      <td>4.6250</td>\n",
              "      <td>1196.0</td>\n",
              "      <td>-0.051282</td>\n",
              "      <td>6140.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6514 rows Ã— 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        PERMNO        date TICKER                    COMNAM      PRC      VOL  \\\n",
              "1079     10006  1984-04-30    ACF      A C F INDUSTRIES INC  52.6250  19428.0   \n",
              "1936     10015  1984-04-30   AMFD   A & M FOOD SERVICES INC  -7.2500   1362.0   \n",
              "4175     10031  1984-04-30   ANTQ         A A IMPORTING INC  -4.3125    203.0   \n",
              "8015     10057  1984-04-30    AMT       ACME CLEVELAND CORP  21.0000   2576.0   \n",
              "8300     10058  1984-04-30   ABKC  A B K C O INDUSTRIES INC  -0.6875      6.0   \n",
              "...        ...         ...    ...                       ...      ...      ...   \n",
              "4018028  90705  1984-04-30   OPTC             OPTELECOM INC  -4.6875   1318.0   \n",
              "4051671  90975  1984-04-30   PEOP          PEOPLES BAN CORP -25.2500    834.0   \n",
              "4206531  92321  1984-04-30    NaN           TAURUS OIL CORP      NaN      NaN   \n",
              "4274787  92946  1984-04-30   VYQT               VYQUEST INC  -5.3125    360.0   \n",
              "4298584  93172  1984-04-30  WINNS          WINN ENTERPRISES   4.6250   1196.0   \n",
              "\n",
              "              RET   SHROUT  \n",
              "1079     0.031863   8385.0  \n",
              "1936     0.104762   3568.0  \n",
              "4175    -0.178571   2683.0  \n",
              "8015     0.004762   6106.0  \n",
              "8300    -0.083333   1089.0  \n",
              "...           ...      ...  \n",
              "4018028 -0.157303   3025.0  \n",
              "4051671  0.052083   3782.0  \n",
              "4206531       NaN  15639.0  \n",
              "4274787 -0.086022   3837.0  \n",
              "4298584 -0.051282   6140.0  \n",
              "\n",
              "[6514 rows x 8 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# print(signal_df.sort_values(by='date'))\n",
        "temp_df = df[df['date'] == '1984-04-30']\n",
        "temp_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RFU4KXgV8hb"
      },
      "source": [
        "Copy and modify the BMDataProcessor to create a IRDataProcessor class. It should load the same `price_df` as before (from the monthly_returns.csv file) but a new `signal_df` with revt, cogs, and lag_at columns (in addition to the date and security_id columns). The lag_at column should contain the prior year's at value, which you can get using the included  `safe_lead_lag` method\n",
        "\n",
        "Let's be very conservative and say we can't rely on having accounting data until 120 days after the end of the fiscal year ('datadate' column). Assume we are willing to use accounting data up to two years old."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhmGW9wKV8hb"
      },
      "source": [
        "***HINT***: be sure to change the `data_folder_path`, `min_accounting_lag`, `max_accounting_lag`, and the constructor `__init__(self)` to reflect the new strategy. The `unique_dates()` and `signal_df_for_date` functions only need to be updated to use datatdate instead of rdq (since we don't have an rdq column in this annual data). These functions will otherwise work as-is, and the other functions don't need to be changed at all."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KVCp-g0aV8hb"
      },
      "outputs": [],
      "source": [
        "# Solution\n",
        "class IRDataProcessor():\n",
        "    \n",
        "    # Path to where we store the data\n",
        "    data_folder_path = Path('') \n",
        "    # Minimum share price to open a new position\n",
        "    min_share_price = 3.0\n",
        "    \n",
        "    # Constructor, loads/cleans/merges data as needed\n",
        "    def __init__(self):\n",
        "        \n",
        "        # Load price data: monthly 1961-2020 sample from CRSP including all public US equities\n",
        "        # In monthly_returns.csv\n",
        "#         self.price_df = pd.read_csv(self.data_folder_path / 'monthly_returns.csv')\n",
        "        \n",
        "        # Parse the yyyyMMdd int dates into DateTime64\n",
        "        # Based on formatting strings here\n",
        "        # https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior\n",
        "#         self.price_df.loc[:,'date'] = pd.to_datetime(self.price_df.loc[:,'date'], format =\"%Y%m%d\")\n",
        "        \n",
        "        # Prices sometimes negative to indicate no volume at closing auction\n",
        "        # In these cases, price = -0.5*(bid+ask)\n",
        "        # But we don't use that information and so want prices to always be positive\n",
        "        # See http://www.crsp.org/products/documentation/data-definitions-p\n",
        "#         self.price_df.loc[:,'prccm'] = np.absolute(self.price_df.loc[:,'prccm'])\n",
        "        \n",
        "        # Add next-months return as a new column 'ret_next'\n",
        "        # Use the safe_lead_lag: want lead return but only when permno the same\n",
        "        # self.price_df.loc[:,'ret_next'] = safe_lead_lag(self.price_df.loc[:,'ret'],self.price_df.loc[:,'permno'],1)\n",
        "        \n",
        "#         self.price_df = self.price_df.dropna()\n",
        "#         self.price_df['market_cap'] = self.price_df['prccm'] * self.price_df['cshom']\n",
        "\n",
        "        # Load accounting data used for BM signal\n",
        "        # Quarterly sample from 1961-2020 from Compustat Fundamentals Quarterly\n",
        "        # Stored in the `comp_bm.dta` file\n",
        "        # `.dta` files are Stata data, and do a better job than `.csv` files of remembering data types\n",
        "        self.signal_df = pd.read_csv(\"crsp_finalproject.csv\", dtype={'PERMNO': 'str', 'date': 'str', 'TICKER': 'str', 'COMNAM': 'str', 'PRC': 'float', 'VOL': 'float', 'RET': 'str', 'SHROUT': 'float'})\n",
        "        self.signal_df = self.signal_df[self.signal_df['date'] >= '1983-06-28']\n",
        "        self.signal_df['RET'] = pd.to_numeric(self.signal_df['RET'], errors='coerce')\n",
        "        self.signal_df['RET'] = self.signal_df['RET'].astype(float)        \n",
        "#         self.signal_df.loc[:, 'lag_at'] = safe_lead_lag(self.signal_df.loc[:, 'at'], self.signal_df.loc[:,'gvkey'], -1)\n",
        "#         self.signal_df.drop('at', axis=1, inplace=True)\n",
        "\n",
        "        self.signal_df['date'] = pd.to_datetime(self.signal_df['date'])\n",
        "        self.signal_df['month'] = pd.DatetimeIndex(self.signal_df['date']).month\n",
        "        self.signal_df['day'] = pd.DatetimeIndex(self.signal_df['date']).day\n",
        "        self.signal_df['year'] = pd.DatetimeIndex(self.signal_df['date']).year\n",
        "        self.signal_df.loc[self.signal_df['month'] == 4, \"day\"] = 30\n",
        "        self.signal_df.loc[self.signal_df['month'] == 6, \"day\"] = 30\n",
        "        import calendar\n",
        "        self.signal_df['date'] = self.signal_df['date'].apply(lambda dt: dt.replace(day=min(calendar.monthrange(dt.year, dt.month)[1],30)))\n",
        "        self.signal_df['PRC'] = self.signal_df['PRC'].abs()\n",
        "        # self.signal_df['date'] = pd.to_datetime(dict(year=self.signal_df.year, month=self.signal_df.month, day=self.signal_df.day))\n",
        "        self.signal_df['market_cap'] = self.signal_df['PRC'] * self.signal_df['SHROUT']\n",
        "        self.signal_df['ret_next'] = safe_lead_lag(self.signal_df.loc[:,'RET'],self.signal_df.loc[:,'PERMNO'],12)\n",
        "        self.signal_df = self.signal_df.dropna()\n",
        "        \n",
        "        #TODO explain why these dates were selected based on Russell 2000 schedule\n",
        "        prediction_date = '04/30'\n",
        "        last_rebalance = '06/30'\n",
        "\n",
        "        self.prediction_date = dt.datetime.strptime(prediction_date, '%m/%d')\n",
        "        self.last_rebalance = dt.datetime.strptime(last_rebalance, '%m/%d')\n",
        "\n",
        "        # The problem with our accounting data is that it identifies stocks using gvkey instead of permno\n",
        "        # To merge with return_df, we need to use another dataset that converts gvkey to permno\n",
        "        # This is stored in the gvkey_permno_conversion.dta file\n",
        "#         self.gvkey_permno_conversion = pd.read_stata(self.data_folder_path / 'gvkey_permno_conversion.dta')\n",
        "\n",
        "        # Use a merge command to add the permno column to our signal_df\n",
        "#         self.signal_df = self.signal_df.merge(self.gvkey_permno_conversion,on=['gvkey','datadate'])           \n",
        "        \n",
        "    # Returns an array with the unique dates for which we have loaded data\n",
        "    # Uses from the price_df since that's how frequency we can update portfolio value\n",
        "    # Filters all dates in price_df to return only dates for which we have signals as well\n",
        "    def unique_dates(self):\n",
        "        temp_df = self.signal_df\n",
        "        # temp_df['date'] = temp_df['date'].apply(lambda dt: dt.replace(day=30) if ((dt.month == 4) | (dt.month == 6)) else dt)\n",
        "        price_dates = pd.Series( np.sort(self.signal_df.loc[:,'date'].unique()) )\n",
        "        return price_dates    \n",
        "    # Returns a DataFrame containing one row for all securities in price_df as of date.\n",
        "    # Columns must include:\n",
        "    # - 'date': date on which price data observed\n",
        "    # - 'security_id': a security identifier\n",
        "    # - 'prc': price on date\n",
        "    # - 'ret': return from previous date to date\n",
        "    # Ignores liquidity and future-return availability requirements\n",
        "    # To be used only for closing decisions and execution decisions\n",
        "    # Some of the returned stocks cannot be traded\n",
        "    def price_df_for_date(self,date):\n",
        "        price_date_df = self.signal_df.loc[ self.signal_df.loc[:,'date'] == date, :]\n",
        "        return price_date_df.rename(columns={'PERMNO':'security_id'}) \n",
        "    \n",
        "    # Returns a DataFrame where each row is a security in the strategy's universe,\n",
        "    # Columes must include:\n",
        "    # - 'date': date on which price data observed\n",
        "    # - 'security_id': a security identifier\n",
        "    # - whatever signals the trading rule needs to decide which securities to open new positions in\n",
        "    #   - In this case, return cshoq, prccq, and ceqq so trading rule can compute B/M ratio\n",
        "    #\n",
        "    # Also responsible for applying whatever liquidity filters are wanted to narrow universe,\n",
        "    # and check that we have future return data (no point in backtesting if we don't know what happens next)\n",
        "    def signal_df_for_date(self,date):\n",
        "        temp_df1 = self.signal_df\n",
        "        # temp_df1 = self.date_filter(temp_df1, self.prediction_date.month, self.last_rebalance.month)\n",
        "        # temp_df1['date'] = temp_df1['date'].apply(lambda dt: dt.replace(day=30))\n",
        "        date_price_df = temp_df1.loc[ temp_df1.loc[:,'date'] == date,:]\n",
        "        date_price_df.rename(columns={'PERMNO':'security_id', 'PRC': 'prc', 'RET': 'ret'}, inplace=True)  # use permno as our security_id        \n",
        "        # and return without the ret_next column so backtests don't cheat by using it\n",
        "        return self.liquidity_filter(date_price_df)\n",
        "    \n",
        "    def filter_and_rank(self,df):\n",
        "        #TODO commenting out for now because I think CRSP may only be US data and we could justify that but not sure\n",
        "        # filtered_df = self.country_filter(self.signal_df)\n",
        "        filtered_df = self.date_filter(df, self.prediction_date.month,self.last_rebalance.month)\n",
        "        filtered_df = filtered_df.loc[ np.isfinite(filtered_df.loc[:,'ret_next']),:]\n",
        "        filtered_df = filtered_df.drop(columns=['ret_next'])\n",
        "  \n",
        "        # TODO: May need to change this since dropping NaN gets rid of too many rows\n",
        "        filtered_df = filtered_df[filtered_df['market_cap'].notna()]\n",
        "        filtered_df.rename(columns={'PERMNO':'security_id', 'PRC': 'prc', 'RET': 'ret'}, inplace=True)  # use permno as our security_id        \n",
        "\n",
        "        # ranking process\n",
        "        return self.rank_by_market_cap(filtered_df)\n",
        "        \n",
        "\n",
        "    # Returns a filterd version of the passed DataFrame,\n",
        "    # with all observations deemefd too illiquid removed\n",
        "    # Liquidity requirements:\n",
        "    #  - price >= $3\n",
        "    def liquidity_filter(self,df):\n",
        "        return df.loc[ df.loc[:,'prc'] >= self.min_share_price,:]\n",
        "\n",
        "    \n",
        "\n",
        "    def country_filter(self, df):\n",
        "        return df.loc[df.loc[:, 'fic'] == 'USA',:]\n",
        "\n",
        "    \n",
        "\n",
        "    def date_filter(self, df, prediction_month, rebalance_month): \n",
        "        condition1 = ((df['month'] == prediction_month))\n",
        "        condition2 = ((df['month'] == rebalance_month))\n",
        "        return df.loc[(condition1 | condition2),:]\n",
        "    \n",
        "    \n",
        "    def rank_by_market_cap(self, df):\n",
        "        df['rank'] = df.groupby(['date'])['market_cap'].rank(ascending=False, method='first')\n",
        "        return df \n",
        "\n",
        "        \n",
        "        \n",
        "###################################################################\n",
        "# Helper methods, do not modify\n",
        "###################################################################\n",
        "\n",
        "# Function safe_lead_lag returns a new Series with the lead/lagged values\n",
        "#  but only when a group is the same for the lead/lag\n",
        "# Inputs:\n",
        "# - data_series: data we want to lead/lag\n",
        "# - group_series: grouping we want to be the same for the lead/lag to be value\n",
        "# requires data_series and group_series already by sorted by group_series\n",
        "# so that all alike values of group_series are adjacent,\n",
        "# meaning group_series should look like:\n",
        "#    g_0\n",
        "#    g_0\n",
        "#    g_0\n",
        "#    g_0\n",
        "#    g_1\n",
        "#    g_1\n",
        "#    g_2\n",
        "#    g_2 \n",
        "#    ...\n",
        "# where g_i indicates the observation is in group i,\n",
        "# and once the first g_{i+1} appears no more g_i values appear\n",
        "# \n",
        "# lead_lag > 0 returns a data_series with values of data_series lead_lag rows ahead\n",
        "# as long as group_series remains the same, NaN if group different\n",
        "# lead_lag < 0 returns a data_series with values of data_series -lead_lag rows behind \n",
        "# (same as lead_lag rows ahead) as long as group_series remains the same, NaN if group different\n",
        "def safe_lead_lag(data_series,group_series,lead_lag): \n",
        "    df = pd.DataFrame({ 'data': data_series, 'group': group_series })\n",
        "    return df.groupby(['group'])['data'].shift(-lead_lag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "nwWMBioJH8wV",
        "outputId": "c32ec176-abac-47a5-c0a7-0cff10109726"
      },
      "outputs": [],
      "source": [
        "temp_processor = IRDataProcessor()\n",
        "temp_df = temp_processor.signal_df\n",
        "temp_df = temp_processor.filter_and_rank(temp_df)\n",
        "temp_df\n",
        "\n",
        "## VERIFIED FINE BY THIS POINT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbotCdXUV8hd"
      },
      "source": [
        "### After running your code above, you should be able to run these tests sucessfully. Please run each cell without editing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HulbXIH_V8hd"
      },
      "source": [
        "#### Constructor tests: should print price_df and signal_df."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkRdf3Q2KyJN",
        "outputId": "9b75aa2b-59c1-470c-b118-e21dace337b7"
      },
      "outputs": [],
      "source": [
        "data_processor = IRDataProcessor()\n",
        "print('\\n\\n', data_processor.signal_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0oR_CCZV8he"
      },
      "source": [
        "#### `ranking_df` test: should return DataFrame with market_cap field ranked by decreasing order on specific dates (4/30 and 6/30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "i8VDQ1nPKyed",
        "outputId": "c29bfa88-3e08-4e57-ea5e-82d99c26bca4"
      },
      "outputs": [],
      "source": [
        "ranked_df = data_processor.filter_and_rank(data_processor.signal_df)\n",
        "ranked_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MY6w6rxTH8wX"
      },
      "source": [
        "#### Try it for a specific date to prove values are sorted/ranked correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "DGiovo7FKyvu",
        "outputId": "4452fa96-5dfe-43c2-9ea1-0400f358d58a"
      },
      "outputs": [],
      "source": [
        "# Prove it works for a specific date - look at 'rank' column\n",
        "test_ranked_df = ranked_df.sort_values(by=['market_cap', 'date'], ascending = False)\n",
        "test_ranked_df = test_ranked_df.loc[(test_ranked_df['date'] == '1998-06-30')]\n",
        "test_ranked_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nAhAy-3H8wX"
      },
      "source": [
        "## Need to build our enter exit signals based on the market cap weights.\n",
        "For Russell 2000: enter signal means market cap was outside of (1001-3000) and is now inside, exit signal means market cap was inside (1001-3000) and is now outside"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ufZ6QcHzH8wX"
      },
      "outputs": [],
      "source": [
        "def index_enter(df, trade_date):\n",
        "    # df_test = df[df['security_id'] == '83011']\n",
        "    # print(df_test)\n",
        "    # df = df[(df['year'] < 2007) & (df['year'] > 2004)]\n",
        "    # df.to_csv(\"DebugFile.csv\")\n",
        "    # Need this df to be all companies whose market cap was outside the range on last rebalance date\n",
        "    #TODO justify in report why we are not doing <1001 as an enter signal (likely a negative sign, company would be exiting other market cap indexes, etc.)\n",
        "    last_rebalance_df = df[(df['month'] == 6) & ((df['rank'] > 3000))] #82403 rows\n",
        "    # print(last_rebalance_df[last_rebalance_df['security_id'] == '83011'])\n",
        "\n",
        "    # Need this df to be all companies whose market cap is inside the range on prediction date\n",
        "    prediction_date_df = df[(df['month'] == 4) & ((df['rank'] >= 1001) & (df['rank'] <= 3000))] #66514 rows\n",
        "    # print(prediction_date_df[prediction_date_df['security_id'] == '83011'])\n",
        "\n",
        "    # Doing some strange manipulation to get a last_rebalance_rank column\n",
        "    last_rebalance_df['date'] = last_rebalance_df['date'] + pd.DateOffset(years=1) - pd.DateOffset(months=2)\n",
        "    # last_rebalance_df['date'] = last_rebalance_df['date'].apply(lambda dt: dt.replace(day=30))\n",
        "    last_rebalance_df = last_rebalance_df.rename(columns={'rank': 'last_rebalance_rank'})\n",
        "    last_rebalance_df = last_rebalance_df[['security_id', 'date','COMNAM', 'last_rebalance_rank']]\n",
        "\n",
        "    merged_df = pd.merge(prediction_date_df, last_rebalance_df)\n",
        "    merged_df['rank_movement'] = (merged_df['last_rebalance_rank'] - merged_df['rank']).abs()\n",
        "    # merged_df.to_csv(\"DebugFile.csv\")\n",
        "    merged_df.drop(['month', 'day'], axis=1, inplace=True)\n",
        "    merged_df = merged_df[merged_df['date'] == trade_date]\n",
        "    merged_df = merged_df.nlargest(20, 'rank_movement')\n",
        "    return merged_df\n",
        "\n",
        "def index_exit(df, trade_date): \n",
        "    # Need this df to be all companies whose market cap was inside the range on last rebalance date\n",
        "    last_rebalance_df = df[(df['month'] == 6) & ((df['rank'] > 1000) & (df['rank'] < 3001))]\n",
        "    # Need this df to be all companies whose market cap is outside the range on prediction date\n",
        "    prediction_date_df = df[(df['month'] == 4) & ((df['rank'] > 3000))]\n",
        "\n",
        "    # Doing some strange manipulation to get a last_rebalance_rank column\n",
        "    last_rebalance_df['date'] = last_rebalance_df['date'] + pd.DateOffset(years=1) - pd.DateOffset(months=2)\n",
        "    # last_rebalance_df['date'] = last_rebalance_df['date'].apply(lambda dt: dt.replace(day=30))\n",
        "    last_rebalance_df = last_rebalance_df.rename(columns={'rank': 'last_rebalance_rank'})\n",
        "    last_rebalance_df = last_rebalance_df[['date', 'TICKER','COMNAM', 'last_rebalance_rank']]\n",
        "\n",
        "    merged_df = pd.merge(prediction_date_df, last_rebalance_df)\n",
        "    merged_df['rank_movement'] = (merged_df['rank'] - merged_df['last_rebalance_rank']).abs()\n",
        "    merged_df.drop(['month', 'day'], axis=1, inplace=True)\n",
        "    merged_df = merged_df[merged_df['date'] == trade_date]\n",
        "    merged_df = merged_df.nlargest(20, 'rank_movement')\n",
        "    return merged_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DT79U7F6V8hf"
      },
      "source": [
        "## <span style=\"color:blue\">Task 4</span>: Create a ProfTradingRule"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3PXfFWtV8hf"
      },
      "source": [
        "This strategy should long stocks that are projected to enter the index and short stocks projected to exit the index, and use equal weighting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "A84G_iYcV8hf"
      },
      "outputs": [],
      "source": [
        "# Solution\n",
        "class IRTradingRule():\n",
        "    # strategy: The index rebalancing strategy forms a new portfolio each month with long positions in firms projected to enter index, and short positions in firms projected to exit index.\n",
        "    # For each $1 NAV, we open $1 total of long positions AND $1 total of short positions\n",
        "    # This would be the max leverage allowed given 50% margin requirements\n",
        "    #\n",
        "    # Assume 100% of portfolio liquidated after each rebalance period and repurchased with new quantities\n",
        "    \n",
        "    # strategy-specifc columns for trades_df (variables we want to keep track of for subsequent analysis)\n",
        "    # usually the variables that led the strategy to open trade in the first place\n",
        "    strategy_specific_trades_df_columns = {'ir': pd.Series([], dtype='float')} \n",
        "    \n",
        "    # minumum number of stocks with available ir for us to actually trade\n",
        "    min_stocks_available = 5\n",
        "\n",
        "    value_weighted = True\n",
        "    \n",
        "    def __init__(self,portfolio_db):\n",
        "        self.portfolio_db = portfolio_db\n",
        "    \n",
        "    # Regardless of the strategy you are implementing, this method must return\n",
        "    # open_trades_df, close_trades_df\n",
        "    #\n",
        "    # open_trades_df is a DataFrame with all the required trades_df columns plus any custom ones for this strategy\n",
        "    #     each row is a new trade the strategy wants to open\n",
        "    #     method only populates the security_id (index) and quantity required columns, plus any custom columns. Rest remain NaN to be populated elsewhere\n",
        "    # close_trades_df is a DataFrame that is a subset of the rows of portfolio_db.trades_df\n",
        "    #     each row is an exist trade the strategy wants to close\n",
        "    #     we don't need to populate any columns in this function\n",
        "    def compute_trades(self,signal_df, date):                \n",
        "        # Since we are doing 100% turnover each period, all currently open trades should be closed\n",
        "        close_trades_df = self.portfolio_db.trades_df.loc[ self.portfolio_db.trades_df.loc[:,'close_datetime'].isna() ,: ].copy()\n",
        "        print(\"CLOSE TRADES LENGTH: \", len(close_trades_df))\n",
        "        # before deciding to open new positions, check that signal_df gives us a big enough set of stocks to actually do this\n",
        "        if( len(signal_df) < self.min_stocks_available ):\n",
        "            return self.empty_trades_df(), close_trades_df       \n",
        "        \n",
        "        # As our gross profitability measure, we'll use annual revenue (REVT), minus annual cost of goods sold (COGS), scaled by prior-year book value of assets (AT)        \n",
        "        # signal_df.loc[:,'gp'] = (signal_df.loc[:,'revt'] - signal_df.loc[:, 'cogs']) / (signal_df.loc[:,'lag_at'])        \n",
        "        # You shouldn't have to change anything below here if you are doing a decile strategy    \n",
        "            \n",
        "        # Find top 10% of signal column      \n",
        "        # need to make a copy because we are going to modify this and don't want to affect signal_df\n",
        "        buys_df = index_enter(signal_df, date)\n",
        "        # Find bottom 10% of signal column\n",
        "        # need to make a copy because we are going to modify this and don't want to affect signal_df\n",
        "        sells_df = index_exit(signal_df, date)\n",
        "        # print(\"BUYS: \", len(buys_df), \"SELLS: \", len(sells_df), \"\\n\")\n",
        "\n",
        "        if( self.value_weighted ): \n",
        "            # Compute value weights\n",
        "            buys_mktcap = buys_df.loc[:,'prc']*buys_df.loc[:,'SHROUT']\n",
        "            buys_w = buys_mktcap / buys_mktcap.sum()\n",
        "            sells_mktcap = sells_df.loc[:,'prc']*sells_df.loc[:,'SHROUT']\n",
        "            sells_w = -sells_mktcap / sells_mktcap.sum() # weights negative because we are selling\n",
        "            \n",
        "            # Dollars per position equal total NAV * buys_w and NAV * sells_w, respectively\n",
        "            buys_dollar = self.portfolio_db.current_nav() * buys_w\n",
        "            buys_df.loc[:,'quantity'] = buys_dollar / buys_df.loc[:,'prc']\n",
        "            sells_dollar = self.portfolio_db.current_nav() * sells_w\n",
        "            sells_df.loc[:,'quantity'] = sells_dollar / sells_df.loc[:,'prc']             \n",
        "                        \n",
        "        else:\n",
        "            # With equal weights we can go directly to dollars per buy/sell\n",
        "            # Which is just NAV / number of positions\n",
        "            dollars_per_buy = self.portfolio_db.current_nav() / len(buys_df)\n",
        "            buys_df['quantity'] = dollars_per_buy / buys_df['prc']\n",
        "      \n",
        "            # figure out quantity per trade by splitting $ evenly\n",
        "            dollars_per_sell = -self.portfolio_db.current_nav() / len(sells_df) # negative because we are selling\n",
        "            sells_df['quantity'] = dollars_per_sell / sells_df['prc'] \n",
        "        open_trades_df = self.empty_trades_df().append(\n",
        "        buys_df.loc[:,['security_id','quantity']]).append(\n",
        "        sells_df.loc[:,['security_id','quantity']])\n",
        "\n",
        "        print(\"OPEN TRADES LENGTH: \", len(open_trades_df))\n",
        "\n",
        "        return open_trades_df, close_trades_df\n",
        "    \n",
        "    # Returns an empty trades_df\n",
        "    # Used so we know the right columns to populate when creating a trades_df else\n",
        "    def empty_trades_df(self):\n",
        "        return pd.concat([self.portfolio_db.empty_trades_df(), pd.DataFrame(self.strategy_specific_trades_df_columns)], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXecovPqV8hf"
      },
      "source": [
        "### After running your code above, you should be able to run these tests sucessfully. Please run each cell without editing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIUdMFkTV8hf"
      },
      "source": [
        "#### `compute_trades` test: should output an open_trades_df with open positions having positive quantity and high gp, close_trades_df negative quantity and low gp, and an empty close_trades_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhGgwIUxV8hg",
        "outputId": "481e8306-94bd-40f1-bc12-8f1c60ca5efd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        PERMNO       date TICKER                     COMNAM         PRC  \\\n",
            "4        10000 1986-04-30  OMFGA  OPTIMUM MANUFACTURING INC     4.00000   \n",
            "23       10001 1986-04-30   GFGC         GREAT FALLS GAS CO     6.37500   \n",
            "25       10001 1986-06-30   GFGC         GREAT FALLS GAS CO     6.12500   \n",
            "35       10001 1987-04-30   GFGC         GREAT FALLS GAS CO     6.12500   \n",
            "37       10001 1987-06-30   GFGC         GREAT FALLS GAS CO     5.87500   \n",
            "...        ...        ...    ...                        ...         ...   \n",
            "4325345  93436 2019-06-30   TSLA                  TESLA INC   223.46001   \n",
            "4325355  93436 2020-04-30   TSLA                  TESLA INC   781.88000   \n",
            "4325357  93436 2020-06-30   TSLA                  TESLA INC  1079.81006   \n",
            "4325367  93436 2021-04-30   TSLA                  TESLA INC   709.44000   \n",
            "4325369  93436 2021-06-30   TSLA                  TESLA INC   679.70001   \n",
            "\n",
            "               VOL       RET    SHROUT  month  day  year    market_cap  \\\n",
            "4            957.0 -0.098592    3793.0      4   30  1986  1.517200e+04   \n",
            "23           225.0  0.009901     985.0      4   30  1986  6.279375e+03   \n",
            "25           238.0 -0.013069     985.0      6   30  1986  6.033125e+03   \n",
            "35           188.0 -0.039216     991.0      4   30  1987  6.069875e+03   \n",
            "37           146.0  0.051429     991.0      6   30  1987  5.822125e+03   \n",
            "...            ...       ...       ...    ...  ...   ...           ...   \n",
            "4325345  2149819.0  0.206848  179118.0      6   30  2019  4.002571e+07   \n",
            "4325355  3806580.0  0.492137  185371.0      4   30  2020  1.449379e+08   \n",
            "4325357  2551787.0  0.293186  186000.0      6   30  2020  2.008447e+08   \n",
            "4325367  6774422.0  0.062147  963330.0      4   30  2021  6.834248e+08   \n",
            "4325369  5186813.0  0.087137  984003.0      6   30  2021  6.688268e+08   \n",
            "\n",
            "         ret_next  \n",
            "4       -0.062500  \n",
            "23      -0.039216  \n",
            "25       0.051429  \n",
            "35       0.030612  \n",
            "37      -0.012039  \n",
            "...           ...  \n",
            "4325345  0.293186  \n",
            "4325355  0.062147  \n",
            "4325357  0.087137  \n",
            "4325367 -0.191945  \n",
            "4325369 -0.111888  \n",
            "\n",
            "[507438 rows x 13 columns]\n",
            "CLOSE TRADES LENGTH:  0\n",
            "OPEN TRADES LENGTH:  40\n"
          ]
        }
      ],
      "source": [
        "%run portfolio_db.ipynb\n",
        "portfolio_db = PortfolioDB()\n",
        "portfolio_db.add_cash(100)\n",
        "\n",
        "data_processor = IRDataProcessor()\n",
        "trading_rule = IRTradingRule(portfolio_db)\n",
        "\n",
        "%run backtest_executor.ipynb\n",
        "executor = BacktestExecutor(portfolio_db)\n",
        "\n",
        "test_date = '1988-04-30'\n",
        "# test_price_df = data_processor.price_df_for_date(test_date)\n",
        "test_signal_df = data_processor.filter_and_rank(data_processor.signal_df)\n",
        "test_open_trades_df, test_close_trades_df = trading_rule.compute_trades(test_signal_df, test_date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcPhhXtFV8hg",
        "outputId": "ca8afb48-71ad-4f00-b9ce-e050269bb23a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_open_trades_df:\n",
            "     security_id   quantity open_datetime  open_average_price close_datetime  \\\n",
            "2578       63263   0.571619           NaT                 NaN            NaT   \n",
            "1984       43043   0.511287           NaT                 NaN            NaT   \n",
            "2218       51748   0.918834           NaT                 NaN            NaT   \n",
            "3281       76428   0.070149           NaT                 NaN            NaT   \n",
            "2546       62439   3.103003           NaT                 NaN            NaT   \n",
            "1073       15238   0.053532           NaT                 NaN            NaT   \n",
            "2801       68638   0.660072           NaT                 NaN            NaT   \n",
            "147        10597   0.213156           NaT                 NaN            NaT   \n",
            "256        11037   0.251195           NaT                 NaN            NaT   \n",
            "2635       64813   0.836057           NaT                 NaN            NaT   \n",
            "7216       93009   5.509581           NaT                 NaN            NaT   \n",
            "2004       43634   0.387709           NaT                 NaN            NaT   \n",
            "19         10064   0.290616           NaT                 NaN            NaT   \n",
            "229        10914   0.444564           NaT                 NaN            NaT   \n",
            "2438       58975   1.094717           NaT                 NaN            NaT   \n",
            "228        10910   0.476929           NaT                 NaN            NaT   \n",
            "1431       19238   0.261523           NaT                 NaN            NaT   \n",
            "2866       70762   0.322827           NaT                 NaN            NaT   \n",
            "1673       29209   0.554593           NaT                 NaN            NaT   \n",
            "1562       24409   4.609920           NaT                 NaN            NaT   \n",
            "4972       78609  -2.026206           NaT                 NaN            NaT   \n",
            "2866       57948  -1.790174           NaT                 NaN            NaT   \n",
            "3499       69083  -3.785026           NaT                 NaN            NaT   \n",
            "183        10556  -2.118260           NaT                 NaN            NaT   \n",
            "7773       89632  -4.749217           NaT                 NaN            NaT   \n",
            "133        10403  -5.597525           NaT                 NaN            NaT   \n",
            "8580       92276  -2.393421           NaT                 NaN            NaT   \n",
            "2786       56120  -2.977353           NaT                 NaN            NaT   \n",
            "7603       89077  -3.164974           NaT                 NaN            NaT   \n",
            "6914       86880  -2.622429           NaT                 NaN            NaT   \n",
            "4967       78543  -4.012780           NaT                 NaN            NaT   \n",
            "3197       64370  -2.786472           NaT                 NaN            NaT   \n",
            "1964       33815 -28.314204           NaT                 NaN            NaT   \n",
            "5914       82473  -0.379757           NaT                 NaN            NaT   \n",
            "3241       65067  -1.516268           NaT                 NaN            NaT   \n",
            "3622       71651  -4.207173           NaT                 NaN            NaT   \n",
            "3419       67555  -3.764709           NaT                 NaN            NaT   \n",
            "3503       69155  -5.318852           NaT                 NaN            NaT   \n",
            "3610       71212  -2.135568           NaT                 NaN            NaT   \n",
            "1420       18817  -2.723764           NaT                 NaN            NaT   \n",
            "\n",
            "      close_average_price  ir  \n",
            "2578                  NaN NaN  \n",
            "1984                  NaN NaN  \n",
            "2218                  NaN NaN  \n",
            "3281                  NaN NaN  \n",
            "2546                  NaN NaN  \n",
            "1073                  NaN NaN  \n",
            "2801                  NaN NaN  \n",
            "147                   NaN NaN  \n",
            "256                   NaN NaN  \n",
            "2635                  NaN NaN  \n",
            "7216                  NaN NaN  \n",
            "2004                  NaN NaN  \n",
            "19                    NaN NaN  \n",
            "229                   NaN NaN  \n",
            "2438                  NaN NaN  \n",
            "228                   NaN NaN  \n",
            "1431                  NaN NaN  \n",
            "2866                  NaN NaN  \n",
            "1673                  NaN NaN  \n",
            "1562                  NaN NaN  \n",
            "4972                  NaN NaN  \n",
            "2866                  NaN NaN  \n",
            "3499                  NaN NaN  \n",
            "183                   NaN NaN  \n",
            "7773                  NaN NaN  \n",
            "133                   NaN NaN  \n",
            "8580                  NaN NaN  \n",
            "2786                  NaN NaN  \n",
            "7603                  NaN NaN  \n",
            "6914                  NaN NaN  \n",
            "4967                  NaN NaN  \n",
            "3197                  NaN NaN  \n",
            "1964                  NaN NaN  \n",
            "5914                  NaN NaN  \n",
            "3241                  NaN NaN  \n",
            "3622                  NaN NaN  \n",
            "3419                  NaN NaN  \n",
            "3503                  NaN NaN  \n",
            "3610                  NaN NaN  \n",
            "1420                  NaN NaN  \n",
            "\n",
            "\n",
            "\n",
            "test_close_trades_df:\n",
            "Empty DataFrame\n",
            "Columns: [security_id, quantity, open_datetime, open_average_price, close_datetime, close_average_price]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "print('test_open_trades_df:')\n",
        "print(test_open_trades_df)\n",
        "\n",
        "print('\\n\\n')\n",
        "print('test_close_trades_df:')\n",
        "print(test_close_trades_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VGuoyVIV8hg"
      },
      "source": [
        "## <span style=\"color:blue\">Task 5</span>: Run the Backtest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtiPSiB-V8hg"
      },
      "source": [
        "If everything above was done correctly, the code in backtest.ipynb should produce a backtest for the gross profitability strategy with a few modifications.\n",
        "\n",
        "Copy the backtest.ipynb code here and modify it as follows:\n",
        "- Adjust the comments and strategy_info dictionary\n",
        "- Do not run bm_data_processor.ipynb and bm_trading_rule.ipynb, as these are no longer needed (the GPDataProcessor and IRTradingRule classes should already be defined above)\n",
        "- Replace the BM versions of data_processor and trading_rule with the GP versions. This should only be two lines of code\n",
        "\n",
        "Nothing else should change."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "9Uz91ND6V8hg"
      },
      "outputs": [],
      "source": [
        "# Solution\n",
        "# Imports\n",
        "from IPython.display import display, Markdown, Latex, clear_output\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "IVG4hU7kV8hg"
      },
      "outputs": [],
      "source": [
        "# # These tools should remain unchanged across strategies unless you have a good reason to change them\n",
        "%run portfolio_db.ipynb\n",
        "%run backtest_executor.ipynb # if you were live trading a strategy, this would be replace by code that submitted orders etc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "busNeStIV8hg"
      },
      "outputs": [],
      "source": [
        "# Step 2: Create the tools we'll need to do the backtest\n",
        "\n",
        "# Data processor, in charge of loading and doling out data\n",
        "data_processor = IRDataProcessor() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "xNEiPGwcV8hh"
      },
      "outputs": [],
      "source": [
        "# Portfolio database, keeps track of all the trades the backtest makes, the strategy NAV, and the current portfolio as we go through the backtest\n",
        "%run portfolio_db.ipynb\n",
        "portfolio_db = PortfolioDB()\n",
        "\n",
        "# Strategy logic, in charge of choosing trades based on current portfolio and data\n",
        "# This exact code would be used for live trading \n",
        "trading_rule = IRTradingRule(portfolio_db)\n",
        "\n",
        "# Trade executor, in charge of \"executing\" trades the strategy decides on, turning them into transactions and updating the portfolio\n",
        "trade_executor = BacktestExecutor(portfolio_db)\n",
        "\n",
        "# Info about the strategy, used for ex-post statistics and output not the actual backtest\n",
        "strategy_info = {\n",
        "    'brief descriptor': 'ir_rebalancing', \n",
        "    'plot descriptor': 'Index Rebalancing Prediction Strategy, Equal-Weighted',\n",
        "    'universe': 'Public US equities eligible for the Russell 2000',\n",
        "    'signals': 'Change in market cap from prior year rebalance date (6/30) to current year prediction date (4/30)',\n",
        "    'trading rule': 'Buy all equities entering 1001-3000 market cap and sell all equities exiting (as the predictor for inclusion/exclusion in Russell 2000), equal-weighted',\n",
        "    'holding period': 'One year',\n",
        "    'periods per year': 12,\n",
        "    'output folder name': 'Output'\n",
        "}\n",
        "\n",
        "# Statistician, used to tabulate and plot statistics after the backtest runs\n",
        "%run backtest_statistician.ipynb\n",
        "statistican = BacktestStatistican(portfolio_db,strategy_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "d-hyMIw7V8hh",
        "outputId": "f625ca6e-1e39-4db9-d42b-0343c0f3b5a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1983-06-30: 100.0 | 0.0'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1983-07-30: 100.0 | 0.0'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1983-08-30: 100.0 | 0.0'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1983-09-30: 100.0 | 0.0'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1983-10-30: 100.0 | 0.0'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1983-11-30: 100.0 | 0.0'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1983-12-30: 100.0 | 0.0'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1984-01-30: 100.0 | 0.0'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1984-02-29: 100.0 | 0.0'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1984-03-30: 100.0 | 0.0'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CLOSE TRADES LENGTH:  0\n",
            "OPEN TRADES LENGTH:  40\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'1984-04-30: 100.0 | 58.62883227175427'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1984-05-30: 94.19878357215597 | 54.37338200182955'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1984-06-30: 91.1001266342405 | 54.31013675764648'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1984-07-30: 92.76191189115866 | 51.91530637581078'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1984-08-30: 97.43402700882518 | 56.570572614713164'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1984-09-30: 96.07689323739564 | 57.26361420752348'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1984-10-30: 95.7997872677278 | 55.3529110903114'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1984-11-30: 99.04030865280525 | 53.9569815932148'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1984-12-30: 102.120103903874 | 54.70770318944286'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1985-01-30: 106.35019086627827 | 60.52530708013277'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1985-02-28: 109.20866590034139 | 62.49542499735204'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1985-03-30: 111.46798697198467 | 63.0773494618117'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CLOSE TRADES LENGTH:  24\n",
            "OPEN TRADES LENGTH:  40\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'1985-04-30: 111.18236296067029 | 89.06094217577142'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1985-05-30: 103.3022221047546 | 88.29871028054659'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1985-06-30: 104.75192345934734 | 92.04886711828273'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1985-07-30: 100.1979653610799 | 90.99104785872933'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1985-08-30: 97.60722856007425 | 89.88559318932928'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1985-09-30: 91.1923832055184 | 83.36316791573933'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1985-10-30: 95.61360606263227 | 90.38925542670565'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1985-11-30: 90.54185934331775 | 93.53927315766451'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1985-12-30: 93.13465534399813 | 98.12814627711553'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1986-01-30: 90.16172723540544 | 102.40275322461163'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1986-02-28: 84.62657542053799 | 107.81423512764421'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1986-03-30: 93.61474871519489 | 113.23442461693388'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CLOSE TRADES LENGTH:  30\n",
            "OPEN TRADES LENGTH:  40\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'1986-04-30: 93.49083594302351 | 93.1863409387723'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1986-05-30: 100.24631748050848 | 101.97445491543377'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1986-06-30: 102.98598269567245 | 108.04730748194015'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1986-07-30: 95.51329011912371 | 95.87841488725809'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1986-08-30: 95.0753293335782 | 101.8311505369943'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1986-09-30: 83.50811340608549 | 96.75796040626088'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1986-10-30: 86.39631964402265 | 97.41199553520744'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1986-11-30: 90.5944036044487 | 95.35229549975881'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1986-12-30: 88.59504789918385 | 93.32663623411881'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1987-01-30: 97.40911857750055 | 104.62251401475288'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1987-02-28: 102.57573141197408 | 112.72294677081786'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1987-03-30: 94.5272544589824 | 113.14479465314446'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CLOSE TRADES LENGTH:  39\n",
            "OPEN TRADES LENGTH:  40\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'1987-04-30: 87.26640428705737 | 105.58626605837335'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'1987-05-30: 92.60784129120339 | 104.92790231537245'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-29-e04ec1567ace>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# dataframes for the date\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mtemp_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_processor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignal_df_for_date\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0msignal_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_processor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_and_rank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_processor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignal_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;31m# price_df = data_processor.price_df_for_date(date)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# Update prices to reflect the new values after however much time has passed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-24-4a3e593511ce>\u001b[0m in \u001b[0;36mfilter_and_rank\u001b[1;34m(self, df)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[1;31m# ranking process\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank_by_market_cap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-24-4a3e593511ce>\u001b[0m in \u001b[0;36mrank_by_market_cap\u001b[1;34m(self, df)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrank_by_market_cap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rank'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'market_cap'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'first'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36mrank\u001b[1;34m(self, method, ascending, na_option, pct, axis)\u001b[0m\n\u001b[0;32m   2297\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"na_option must be one of 'keep', 'top', or 'bottom'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2298\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2299\u001b[1;33m         return self._cython_transform(\n\u001b[0m\u001b[0;32m   2300\u001b[0m             \u001b[1;34m\"rank\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2301\u001b[0m             \u001b[0mnumeric_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m_cython_transform\u001b[1;34m(self, how, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m                 \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    962\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\ops.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, values, how, axis, **kwargs)\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cython_operation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"transform\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m     def _aggregate(\n",
            "\u001b[1;32mc:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\ops.py\u001b[0m in \u001b[0;36m_cython_operation\u001b[1;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[1;31m# TODO: min_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 544\u001b[1;33m             result = self._transform(\n\u001b[0m\u001b[0;32m    545\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_datetimelike\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m             )\n",
            "\u001b[1;32mc:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\ops.py\u001b[0m in \u001b[0;36m_transform\u001b[1;34m(self, result, values, comp_ids, transform_func, is_datetimelike, **kwargs)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[0mcomp_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m         \u001b[0mtransform_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomp_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mngroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_datetimelike\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mpandas\\_libs\\groupby.pyx\u001b[0m in \u001b[0;36mpandas._libs.groupby.group_rank\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mlexsort\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Step 3: Run actual backtest\n",
        "# Do NOT edit this cell without a very good reason\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# Add 100 initial cash to our portfolios\n",
        "portfolio_db.add_cash(100)\n",
        "\n",
        "# Get our list of unique dates\n",
        "udates = data_processor.unique_dates()\n",
        "\n",
        "# Main loop for the backtest\n",
        "for date in udates:\n",
        "    # dataframes for the date\n",
        "    temp_df = data_processor.signal_df_for_date(date)\n",
        "    signal_df = data_processor.filter_and_rank(data_processor.signal_df)\n",
        "    # price_df = data_processor.price_df_for_date(date)\n",
        "    # Update prices to reflect the new values after however much time has passed\n",
        "    # Need to do this first each date because the updated prices may affect our trading rule\n",
        "    portfolio_db.update_prices(temp_df)\n",
        "    \n",
        "    if date.month == 4: \n",
        "        # Ask the trading rule what trades we should make\n",
        "        open_trades_df, close_trades_df = trading_rule.compute_trades(signal_df=signal_df, date=date)\n",
        "        # apply dates to trades\n",
        "        open_trades_df.loc[:,'open_datetime'] = date\n",
        "        close_trades_df.loc[:,'close_datetime'] = date\n",
        "\n",
        "        # execute trades\n",
        "        trade_executor.execute_opens(open_trades_df=open_trades_df, price_df=temp_df)\n",
        "        trade_executor.execute_closes(close_trades_df=close_trades_df, price_df=temp_df) \n",
        "    # Record account data for today\n",
        "    portfolio_db.record_account_data(price_df=temp_df,datetime=date)\n",
        "    \n",
        "    # Do some fancy output tracking our NAV and margin requirement each day\n",
        "    # clear_output(wait=True)\n",
        "    display( np.datetime_as_string(np.datetime64(date), unit='D') + ': ' + str(portfolio_db.current_nav()) + \" | \" + str(portfolio_db.current_margin()))\n",
        "# Now that the loop is done, tell the statistican to output stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "The indices for endog and exog are not aligned",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-27-bca80811853b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstatistican\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-25-55a0546b6e60>\u001b[0m in \u001b[0;36moutput_stats\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;31m# Run the regression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlhs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrhs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\trent\\anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    870\u001b[0m     def __init__(self, endog, exog=None, missing='none', hasconst=None,\n\u001b[0;32m    871\u001b[0m                  **kwargs):\n\u001b[1;32m--> 872\u001b[1;33m         super(OLS, self).__init__(endog, exog, missing=missing,\n\u001b[0m\u001b[0;32m    873\u001b[0m                                   hasconst=hasconst, **kwargs)\n\u001b[0;32m    874\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"weights\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_keys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\trent\\anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    701\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m             \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m         super(WLS, self).__init__(endog, exog, missing=missing,\n\u001b[0m\u001b[0;32m    704\u001b[0m                                   weights=weights, hasconst=hasconst, **kwargs)\n\u001b[0;32m    705\u001b[0m         \u001b[0mnobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\trent\\anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    188\u001b[0m     \"\"\"\n\u001b[0;32m    189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRegressionModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_attr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pinv_wexog'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\trent\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLikelihoodModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\trent\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mmissing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'missing'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'none'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mhasconst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hasconst'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         self.data = self._handle_data(endog, exog, missing, hasconst,\n\u001b[0m\u001b[0;32m     78\u001b[0m                                       **kwargs)\n\u001b[0;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_constant\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\trent\\anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36m_handle_data\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m         \u001b[1;31m# kwargs arrays could have changed, easier to just attach here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\trent\\anaconda3\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36mhandle_data\u001b[1;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m     \u001b[0mklass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_data_class_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m     return klass(endog, exog=exog, missing=missing, hasconst=hasconst,\n\u001b[0m\u001b[0;32m    673\u001b[0m                  **kwargs)\n",
            "\u001b[1;32mc:\\Users\\trent\\anaconda3\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhasconst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\trent\\anaconda3\\lib\\site-packages\\statsmodels\\base\\data.py\u001b[0m in \u001b[0;36m_check_integrity\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    530\u001b[0m                 \u001b[1;33m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'index'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'index'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m                 not self.orig_endog.index.equals(self.orig_exog.index)):\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The indices for endog and exog are not aligned\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPandasData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: The indices for endog and exog are not aligned"
          ]
        }
      ],
      "source": [
        "statistican.output_stats()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "08aaebccf46177101be16f6e26ae2889575a915459ea24a9bfd89d18fb6b39fb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
