{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmRbPqCoV8hW"
   },
   "source": [
    "# <span style=\"color:blue\">Quant Final Project</span>\n",
    "## Finance 372 - Prof Travis Johnson"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "rY2TsKH4V8hY"
   },
   "source": [
    "## Solution by: <span style=\"color:orange\">Trent Becker, Arjun Nair, Madhavan Uchani </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RXYIbw3rV8hY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "WpnDfGn0V8hZ",
    "outputId": "1df38b97-dd0a-45d5-a650-839c1e3704e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trent\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# Solution\n",
    "# signal_df = pd.read_stata(\"final_project_data.dta\")\n",
    "#TODO --> Determine if we need the foreign identifier code from compustat data or if we can justify not needing it\n",
    "df = pd.read_csv(\"crsp_finalproject.csv\")\n",
    "df = df[df['date'] >= '1983-06-28']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4x8huJPhV8hZ"
   },
   "source": [
    "Now remove unnecessary columns, keeping only gvkey, datadate, at, cogs, and revt. Write the edited dataframe into a .dta file using `.to_stata('gp_data.dta',write_index=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "X_A8xzlAV8hZ"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "#signal_df = signal_df[['PERMNO', 'date', 'TICKER', 'COMNAM', 'PRC', 'VOL', 'RET', 'SHROUT']]\n",
    "#signal_df.to_stata('index_rebalancing_data.dta', write_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJKZFr4rV8ha"
   },
   "source": [
    "Run this cell without editing it to show us what your signal_df looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "wlFy9pWHV8ha",
    "outputId": "d3c99518-409a-46d1-af95-6cf22b66426d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>date</th>\n",
       "      <th>TICKER</th>\n",
       "      <th>COMNAM</th>\n",
       "      <th>PRC</th>\n",
       "      <th>VOL</th>\n",
       "      <th>RET</th>\n",
       "      <th>SHROUT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>10006</td>\n",
       "      <td>1984-04-30</td>\n",
       "      <td>ACF</td>\n",
       "      <td>A C F INDUSTRIES INC</td>\n",
       "      <td>52.6250</td>\n",
       "      <td>19428.0</td>\n",
       "      <td>0.031863</td>\n",
       "      <td>8385.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>10015</td>\n",
       "      <td>1984-04-30</td>\n",
       "      <td>AMFD</td>\n",
       "      <td>A &amp; M FOOD SERVICES INC</td>\n",
       "      <td>-7.2500</td>\n",
       "      <td>1362.0</td>\n",
       "      <td>0.104762</td>\n",
       "      <td>3568.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>10031</td>\n",
       "      <td>1984-04-30</td>\n",
       "      <td>ANTQ</td>\n",
       "      <td>A A IMPORTING INC</td>\n",
       "      <td>-4.3125</td>\n",
       "      <td>203.0</td>\n",
       "      <td>-0.178571</td>\n",
       "      <td>2683.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8015</th>\n",
       "      <td>10057</td>\n",
       "      <td>1984-04-30</td>\n",
       "      <td>AMT</td>\n",
       "      <td>ACME CLEVELAND CORP</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>2576.0</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>6106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8300</th>\n",
       "      <td>10058</td>\n",
       "      <td>1984-04-30</td>\n",
       "      <td>ABKC</td>\n",
       "      <td>A B K C O INDUSTRIES INC</td>\n",
       "      <td>-0.6875</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>1089.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4018028</th>\n",
       "      <td>90705</td>\n",
       "      <td>1984-04-30</td>\n",
       "      <td>OPTC</td>\n",
       "      <td>OPTELECOM INC</td>\n",
       "      <td>-4.6875</td>\n",
       "      <td>1318.0</td>\n",
       "      <td>-0.157303</td>\n",
       "      <td>3025.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4051671</th>\n",
       "      <td>90975</td>\n",
       "      <td>1984-04-30</td>\n",
       "      <td>PEOP</td>\n",
       "      <td>PEOPLES BAN CORP</td>\n",
       "      <td>-25.2500</td>\n",
       "      <td>834.0</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>3782.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4206531</th>\n",
       "      <td>92321</td>\n",
       "      <td>1984-04-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TAURUS OIL CORP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>15639.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274787</th>\n",
       "      <td>92946</td>\n",
       "      <td>1984-04-30</td>\n",
       "      <td>VYQT</td>\n",
       "      <td>VYQUEST INC</td>\n",
       "      <td>-5.3125</td>\n",
       "      <td>360.0</td>\n",
       "      <td>-0.086022</td>\n",
       "      <td>3837.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4298584</th>\n",
       "      <td>93172</td>\n",
       "      <td>1984-04-30</td>\n",
       "      <td>WINNS</td>\n",
       "      <td>WINN ENTERPRISES</td>\n",
       "      <td>4.6250</td>\n",
       "      <td>1196.0</td>\n",
       "      <td>-0.051282</td>\n",
       "      <td>6140.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6514 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PERMNO        date TICKER                    COMNAM      PRC  \\\n",
       "1079      10006  1984-04-30    ACF      A C F INDUSTRIES INC  52.6250   \n",
       "1936      10015  1984-04-30   AMFD   A & M FOOD SERVICES INC  -7.2500   \n",
       "4175      10031  1984-04-30   ANTQ         A A IMPORTING INC  -4.3125   \n",
       "8015      10057  1984-04-30    AMT       ACME CLEVELAND CORP  21.0000   \n",
       "8300      10058  1984-04-30   ABKC  A B K C O INDUSTRIES INC  -0.6875   \n",
       "...         ...         ...    ...                       ...      ...   \n",
       "4018028   90705  1984-04-30   OPTC             OPTELECOM INC  -4.6875   \n",
       "4051671   90975  1984-04-30   PEOP          PEOPLES BAN CORP -25.2500   \n",
       "4206531   92321  1984-04-30    NaN           TAURUS OIL CORP      NaN   \n",
       "4274787   92946  1984-04-30   VYQT               VYQUEST INC  -5.3125   \n",
       "4298584   93172  1984-04-30  WINNS          WINN ENTERPRISES   4.6250   \n",
       "\n",
       "             VOL        RET   SHROUT  \n",
       "1079     19428.0   0.031863   8385.0  \n",
       "1936      1362.0   0.104762   3568.0  \n",
       "4175       203.0  -0.178571   2683.0  \n",
       "8015      2576.0   0.004762   6106.0  \n",
       "8300         6.0  -0.083333   1089.0  \n",
       "...          ...        ...      ...  \n",
       "4018028   1318.0  -0.157303   3025.0  \n",
       "4051671    834.0   0.052083   3782.0  \n",
       "4206531      NaN          B  15639.0  \n",
       "4274787    360.0  -0.086022   3837.0  \n",
       "4298584   1196.0  -0.051282   6140.0  \n",
       "\n",
       "[6514 rows x 8 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(signal_df.sort_values(by='date'))\n",
    "temp_df = df[df['date'] == '1984-04-30']\n",
    "temp_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_RFU4KXgV8hb"
   },
   "source": [
    "Copy and modify the BMDataProcessor to create a IRDataProcessor class. It should load the same `price_df` as before (from the monthly_returns.csv file) but a new `signal_df` with revt, cogs, and lag_at columns (in addition to the date and security_id columns). The lag_at column should contain the prior year's at value, which you can get using the included  `safe_lead_lag` method\n",
    "\n",
    "Let's be very conservative and say we can't rely on having accounting data until 120 days after the end of the fiscal year ('datadate' column). Assume we are willing to use accounting data up to two years old."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhmGW9wKV8hb"
   },
   "source": [
    "***HINT***: be sure to change the `data_folder_path`, `min_accounting_lag`, `max_accounting_lag`, and the constructor `__init__(self)` to reflect the new strategy. The `unique_dates()` and `signal_df_for_date` functions only need to be updated to use datatdate instead of rdq (since we don't have an rdq column in this annual data). These functions will otherwise work as-is, and the other functions don't need to be changed at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "KVCp-g0aV8hb"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "class IRDataProcessor():\n",
    "    \n",
    "    # Path to where we store the data\n",
    "    data_folder_path = Path('') \n",
    "    # Minimum share price to open a new position\n",
    "    min_share_price = 3.0\n",
    "    \n",
    "    # Constructor, loads/cleans/merges data as needed\n",
    "    def __init__(self):\n",
    "        \n",
    "        # Load price data: monthly 1961-2020 sample from CRSP including all public US equities\n",
    "        # In monthly_returns.csv\n",
    "#         self.price_df = pd.read_csv(self.data_folder_path / 'monthly_returns.csv')\n",
    "        \n",
    "        # Parse the yyyyMMdd int dates into DateTime64\n",
    "        # Based on formatting strings here\n",
    "        # https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior\n",
    "#         self.price_df.loc[:,'date'] = pd.to_datetime(self.price_df.loc[:,'date'], format =\"%Y%m%d\")\n",
    "        \n",
    "        # Prices sometimes negative to indicate no volume at closing auction\n",
    "        # In these cases, price = -0.5*(bid+ask)\n",
    "        # But we don't use that information and so want prices to always be positive\n",
    "        # See http://www.crsp.org/products/documentation/data-definitions-p\n",
    "#         self.price_df.loc[:,'prccm'] = np.absolute(self.price_df.loc[:,'prccm'])\n",
    "        \n",
    "        # Add next-months return as a new column 'ret_next'\n",
    "        # Use the safe_lead_lag: want lead return but only when permno the same\n",
    "        # self.price_df.loc[:,'ret_next'] = safe_lead_lag(self.price_df.loc[:,'ret'],self.price_df.loc[:,'permno'],1)\n",
    "        \n",
    "#         self.price_df = self.price_df.dropna()\n",
    "#         self.price_df['market_cap'] = self.price_df['prccm'] * self.price_df['cshom']\n",
    "\n",
    "        # Load accounting data used for BM signal\n",
    "        # Quarterly sample from 1961-2020 from Compustat Fundamentals Quarterly\n",
    "        # Stored in the `comp_bm.dta` file\n",
    "        # `.dta` files are Stata data, and do a better job than `.csv` files of remembering data types\n",
    "        self.signal_df = pd.read_csv(\"crsp_finalproject.csv\")\n",
    "        self.signal_df = self.signal_df[self.signal_df['date'] >= '1983-06-28']        \n",
    "#         self.signal_df.loc[:, 'lag_at'] = safe_lead_lag(self.signal_df.loc[:, 'at'], self.signal_df.loc[:,'gvkey'], -1)\n",
    "#         self.signal_df.drop('at', axis=1, inplace=True)\n",
    "\n",
    "        self.signal_df['date'] = pd.to_datetime(self.signal_df['date'])\n",
    "        self.signal_df['month'] = pd.DatetimeIndex(self.signal_df['date']).month\n",
    "        self.signal_df['day'] = pd.DatetimeIndex(self.signal_df['date']).day\n",
    "        self.signal_df['year'] = pd.DatetimeIndex(self.signal_df['date']).year\n",
    "        self.signal_df.loc[self.signal_df['month'] == 4, \"day\"] = 30\n",
    "        self.signal_df['date'] = pd.to_datetime(dict(year=self.signal_df.year, month=self.signal_df.month, day=self.signal_df.day))\n",
    "        self.signal_df['market_cap'] = self.signal_df['PRC'] * self.signal_df['SHROUT']\n",
    "        self.signal_df = self.signal_df.dropna()\n",
    "        \n",
    "        #TODO explain why these dates were selected based on Russell 2000 schedule\n",
    "        prediction_date = '04/30'\n",
    "        last_rebalance = '06/30'\n",
    "\n",
    "        self.prediction_date = dt.datetime.strptime(prediction_date, '%m/%d')\n",
    "        self.last_rebalance = dt.datetime.strptime(last_rebalance, '%m/%d')\n",
    "        # The problem with our accounting data is that it identifies stocks using gvkey instead of permno\n",
    "        # To merge with return_df, we need to use another dataset that converts gvkey to permno\n",
    "        # This is stored in the gvkey_permno_conversion.dta file\n",
    "#         self.gvkey_permno_conversion = pd.read_stata(self.data_folder_path / 'gvkey_permno_conversion.dta')\n",
    "\n",
    "        # Use a merge command to add the permno column to our signal_df\n",
    "#         self.signal_df = self.signal_df.merge(self.gvkey_permno_conversion,on=['gvkey','datadate'])           \n",
    "        \n",
    "    # Returns an array with the unique dates for which we have loaded data\n",
    "    # Uses from the price_df since that's how frequency we can update portfolio value\n",
    "    # Filters all dates in price_df to return only dates for which we have signals as well\n",
    "    def unique_dates(self):\n",
    "        price_dates = pd.Series( np.sort(self.signal_df.loc[:,'date'].unique()) )\n",
    "        return price_dates    \n",
    "    # Returns a DataFrame containing one row for all securities in price_df as of date.\n",
    "    # Columns must include:\n",
    "    # - 'date': date on which price data observed\n",
    "    # - 'security_id': a security identifier\n",
    "    # - 'prc': price on date\n",
    "    # - 'ret': return from previous date to date\n",
    "    # Ignores liquidity and future-return availability requirements\n",
    "    # To be used only for closing decisions and execution decisions\n",
    "    # Some of the returned stocks cannot be traded\n",
    "    def price_df_for_date(self,date):\n",
    "        price_date_df = self.signal_df.loc[ self.signal_df.loc[:,'date'] == date, :]\n",
    "        return price_date_df.rename(columns={'PERMNO':'security_id'}) \n",
    "    \n",
    "    # Returns a DataFrame where each row is a security in the strategy's universe,\n",
    "    # Columes must include:\n",
    "    # - 'date': date on which price data observed\n",
    "    # - 'security_id': a security identifier\n",
    "    # - whatever signals the trading rule needs to decide which securities to open new positions in\n",
    "    #   - In this case, return cshoq, prccq, and ceqq so trading rule can compute B/M ratio\n",
    "    #\n",
    "    # Also responsible for applying whatever liquidity filters are wanted to narrow universe,\n",
    "    # and check that we have future return data (no point in backtesting if we don't know what happens next)\n",
    "    def signal_df_for_date(self,date):\n",
    "        date_price_df = self.signal_df.loc[ self.signal_df.loc[:,'date'] == date,:]\n",
    "        date_price_df.rename(columns={'PERMNO':'security_id', 'PRC': 'prc', 'RET': 'ret'}, inplace=True)  # use permno as our security_id        \n",
    "        # and return without the ret_next column so backtests don't cheat by using it\n",
    "        return self.liquidity_filter(date_price_df)\n",
    "    \n",
    "    def filter_and_rank(self,df):\n",
    "        #TODO commenting out for now because I think CRSP may only be US data and we could justify that but not sure\n",
    "        # filtered_df = self.country_filter(self.signal_df)\n",
    "        filtered_df = self.date_filter(df, self.prediction_date.month, self.prediction_date.day, self.last_rebalance.month, self.last_rebalance.day)\n",
    "        \n",
    "        # TODO: May need to change this since dropping NaN gets rid of too many rows\n",
    "        filtered_df = filtered_df[filtered_df['market_cap'].notna()]\n",
    "        filtered_df.rename(columns={'PERMNO':'security_id', 'PRC': 'prc', 'RET': 'ret'}, inplace=True)  # use permno as our security_id        \n",
    "\n",
    "        # ranking process\n",
    "        return self.rank_by_market_cap(filtered_df)\n",
    "        \n",
    "\n",
    "    # Returns a filterd version of the passed DataFrame,\n",
    "    # with all observations deemefd too illiquid removed\n",
    "    # Liquidity requirements:\n",
    "    #  - price >= $3\n",
    "    def liquidity_filter(self,df):\n",
    "        return df.loc[ df.loc[:,'prc'] >= self.min_share_price,:]\n",
    "\n",
    "    \n",
    "\n",
    "    def country_filter(self, df):\n",
    "        return df.loc[df.loc[:, 'fic'] == 'USA',:]\n",
    "\n",
    "    \n",
    "\n",
    "    def date_filter(self, df, prediction_month, prediction_day, rebalance_month, rebalance_day): \n",
    "        condition1 = ((df['month'] == prediction_month) & (df['day'] == prediction_day))\n",
    "        condition2 = ((df['month'] == rebalance_month) & (df['day'] == rebalance_day))\n",
    "        return df.loc[(condition1 | condition2),:]\n",
    "    \n",
    "    \n",
    "    def rank_by_market_cap(self, df):\n",
    "        df['rank'] = df.groupby(['date'])['market_cap'].rank(ascending=False)\n",
    "        return df \n",
    "\n",
    "        \n",
    "        \n",
    "###################################################################\n",
    "# Helper methods, do not modify\n",
    "###################################################################\n",
    "\n",
    "# Function safe_lead_lag returns a new Series with the lead/lagged values\n",
    "#  but only when a group is the same for the lead/lag\n",
    "# Inputs:\n",
    "# - data_series: data we want to lead/lag\n",
    "# - group_series: grouping we want to be the same for the lead/lag to be value\n",
    "# requires data_series and group_series already by sorted by group_series\n",
    "# so that all alike values of group_series are adjacent,\n",
    "# meaning group_series should look like:\n",
    "#    g_0\n",
    "#    g_0\n",
    "#    g_0\n",
    "#    g_0\n",
    "#    g_1\n",
    "#    g_1\n",
    "#    g_2\n",
    "#    g_2 \n",
    "#    ...\n",
    "# where g_i indicates the observation is in group i,\n",
    "# and once the first g_{i+1} appears no more g_i values appear\n",
    "# \n",
    "# lead_lag > 0 returns a data_series with values of data_series lead_lag rows ahead\n",
    "# as long as group_series remains the same, NaN if group different\n",
    "# lead_lag < 0 returns a data_series with values of data_series -lead_lag rows behind \n",
    "# (same as lead_lag rows ahead) as long as group_series remains the same, NaN if group different\n",
    "def safe_lead_lag(data_series,group_series,lead_lag): \n",
    "    df = pd.DataFrame({ 'data': data_series, 'group': group_series })\n",
    "    return df.groupby(['group'])['data'].shift(-lead_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trent\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3338: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>security_id</th>\n",
       "      <th>date</th>\n",
       "      <th>TICKER</th>\n",
       "      <th>COMNAM</th>\n",
       "      <th>prc</th>\n",
       "      <th>VOL</th>\n",
       "      <th>ret</th>\n",
       "      <th>SHROUT</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>1986-04-30</td>\n",
       "      <td>OMFGA</td>\n",
       "      <td>OPTIMUM MANUFACTURING INC</td>\n",
       "      <td>-4.00000</td>\n",
       "      <td>957.0</td>\n",
       "      <td>-0.098592</td>\n",
       "      <td>3793.0</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>1986</td>\n",
       "      <td>-1.517200e+04</td>\n",
       "      <td>5640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10000</td>\n",
       "      <td>1986-06-30</td>\n",
       "      <td>OMFGA</td>\n",
       "      <td>OPTIMUM MANUFACTURING INC</td>\n",
       "      <td>-3.09375</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>-0.005025</td>\n",
       "      <td>3793.0</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>1986</td>\n",
       "      <td>-1.173459e+04</td>\n",
       "      <td>5559.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10000</td>\n",
       "      <td>1987-04-30</td>\n",
       "      <td>OMFGA</td>\n",
       "      <td>OPTIMUM MANUFACTURING INC</td>\n",
       "      <td>-0.23438</td>\n",
       "      <td>998.0</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>3893.0</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>1987</td>\n",
       "      <td>-9.124413e+02</td>\n",
       "      <td>4887.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10001</td>\n",
       "      <td>1986-04-30</td>\n",
       "      <td>GFGC</td>\n",
       "      <td>GREAT FALLS GAS CO</td>\n",
       "      <td>-6.37500</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>985.0</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>1986</td>\n",
       "      <td>-6.279375e+03</td>\n",
       "      <td>5110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10001</td>\n",
       "      <td>1986-06-30</td>\n",
       "      <td>GFGC</td>\n",
       "      <td>GREAT FALLS GAS CO</td>\n",
       "      <td>-6.12500</td>\n",
       "      <td>238.0</td>\n",
       "      <td>-0.013069</td>\n",
       "      <td>985.0</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>1986</td>\n",
       "      <td>-6.033125e+03</td>\n",
       "      <td>5125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325357</th>\n",
       "      <td>93436</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>TESLA INC</td>\n",
       "      <td>1079.81006</td>\n",
       "      <td>2551787.0</td>\n",
       "      <td>0.293186</td>\n",
       "      <td>186000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>2020</td>\n",
       "      <td>2.008447e+08</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325367</th>\n",
       "      <td>93436</td>\n",
       "      <td>2021-04-30</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>TESLA INC</td>\n",
       "      <td>709.44000</td>\n",
       "      <td>6774422.0</td>\n",
       "      <td>0.062147</td>\n",
       "      <td>963330.0</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>2021</td>\n",
       "      <td>6.834248e+08</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325369</th>\n",
       "      <td>93436</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>TESLA INC</td>\n",
       "      <td>679.70001</td>\n",
       "      <td>5186813.0</td>\n",
       "      <td>0.087137</td>\n",
       "      <td>984003.0</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>2021</td>\n",
       "      <td>6.688268e+08</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325379</th>\n",
       "      <td>93436</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>TESLA INC</td>\n",
       "      <td>870.76001</td>\n",
       "      <td>5046142.0</td>\n",
       "      <td>-0.191945</td>\n",
       "      <td>1036010.0</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>2022</td>\n",
       "      <td>9.021161e+08</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4325381</th>\n",
       "      <td>93436</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>TESLA INC</td>\n",
       "      <td>673.41998</td>\n",
       "      <td>6684634.0</td>\n",
       "      <td>-0.111888</td>\n",
       "      <td>1041000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>2022</td>\n",
       "      <td>7.010302e+08</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>486058 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         security_id       date TICKER                     COMNAM         prc  \\\n",
       "4              10000 1986-04-30  OMFGA  OPTIMUM MANUFACTURING INC    -4.00000   \n",
       "6              10000 1986-06-30  OMFGA  OPTIMUM MANUFACTURING INC    -3.09375   \n",
       "16             10000 1987-04-30  OMFGA  OPTIMUM MANUFACTURING INC    -0.23438   \n",
       "23             10001 1986-04-30   GFGC         GREAT FALLS GAS CO    -6.37500   \n",
       "25             10001 1986-06-30   GFGC         GREAT FALLS GAS CO    -6.12500   \n",
       "...              ...        ...    ...                        ...         ...   \n",
       "4325357        93436 2020-06-30   TSLA                  TESLA INC  1079.81006   \n",
       "4325367        93436 2021-04-30   TSLA                  TESLA INC   709.44000   \n",
       "4325369        93436 2021-06-30   TSLA                  TESLA INC   679.70001   \n",
       "4325379        93436 2022-04-30   TSLA                  TESLA INC   870.76001   \n",
       "4325381        93436 2022-06-30   TSLA                  TESLA INC   673.41998   \n",
       "\n",
       "               VOL        ret     SHROUT  month  day  year    market_cap  \\\n",
       "4            957.0  -0.098592     3793.0      4   30  1986 -1.517200e+04   \n",
       "6           1069.0  -0.005025     3793.0      6   30  1986 -1.173459e+04   \n",
       "16           998.0  -0.062500     3893.0      4   30  1987 -9.124413e+02   \n",
       "23           225.0   0.009901      985.0      4   30  1986 -6.279375e+03   \n",
       "25           238.0  -0.013069      985.0      6   30  1986 -6.033125e+03   \n",
       "...            ...        ...        ...    ...  ...   ...           ...   \n",
       "4325357  2551787.0   0.293186   186000.0      6   30  2020  2.008447e+08   \n",
       "4325367  6774422.0   0.062147   963330.0      4   30  2021  6.834248e+08   \n",
       "4325369  5186813.0   0.087137   984003.0      6   30  2021  6.688268e+08   \n",
       "4325379  5046142.0  -0.191945  1036010.0      4   30  2022  9.021161e+08   \n",
       "4325381  6684634.0  -0.111888  1041000.0      6   30  2022  7.010302e+08   \n",
       "\n",
       "           rank  \n",
       "4        5640.0  \n",
       "6        5559.0  \n",
       "16       4887.0  \n",
       "23       5110.0  \n",
       "25       5125.0  \n",
       "...         ...  \n",
       "4325357    26.0  \n",
       "4325367     7.0  \n",
       "4325369     7.0  \n",
       "4325379     4.0  \n",
       "4325381     4.0  \n",
       "\n",
       "[486058 rows x 13 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_processor = IRDataProcessor()\n",
    "temp_df = temp_processor.signal_df\n",
    "temp_df = temp_processor.filter_and_rank(temp_df)\n",
    "temp_df\n",
    "\n",
    "## VERIFIED FINE BY THIS POINT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbotCdXUV8hd"
   },
   "source": [
    "### After running your code above, you should be able to run these tests sucessfully. Please run each cell without editing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HulbXIH_V8hd"
   },
   "source": [
    "#### Constructor tests: should print price_df and signal_df."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "d0oR_CCZV8he"
   },
   "source": [
    "#### `ranking_df` test: should return DataFrame with market_cap field ranked by decreasing order on specific dates (4/30 and 6/30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try it for a specific date to prove values are sorted/ranked correctly."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to build our enter exit signals based on the market cap weights.\n",
    "For Russell 2000: enter signal means market cap was outside of (1001-3000) and is now inside, exit signal means market cap was inside (1001-3000) and is now outside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_enter(df):\n",
    "    # Need this df to be all companies whose market cap was outside the range on last rebalance date\n",
    "    #TODO justify in report why we are not doing <1001 as an enter signal (likely a negative sign, company would be exiting other market cap indexes, etc.)\n",
    "    last_rebalance_df = df[(df['month'] == 6) & (df['rank'] > 3000)] #82403 rows\n",
    "    # Need this df to be all companies whose market cap is inside the range on prediction date\n",
    "    prediction_date_df = df[(df['month'] == 4) & (df['rank'] > 1000) & (df['rank'] < 3001)] #66514 rows\n",
    "\n",
    "    # Doing some strange manipulation to get a last_rebalance_rank column\n",
    "    last_rebalance_df['date'] = last_rebalance_df['date'] + pd.DateOffset(years=1) - pd.DateOffset(months=2)\n",
    "    last_rebalance_df = last_rebalance_df.rename(columns={'rank': 'last_rebalance_rank'})\n",
    "    last_rebalance_df = last_rebalance_df[['date', 'TICKER','COMNAM', 'last_rebalance_rank']]\n",
    "\n",
    "    merged_df = pd.merge(prediction_date_df, last_rebalance_df)\n",
    "    merged_df.drop(['month', 'day'], axis=1, inplace=True)\n",
    "    return merged_df\n",
    "\n",
    "def index_exit(df): \n",
    "    # Need this df to be all companies whose market cap was inside the range on last rebalance date\n",
    "    last_rebalance_df = df[(df['month'] == 6) & (df['rank'] > 1000) & (df['rank'] < 3001)]\n",
    "    # Need this df to be all companies whose market cap is outside the range on prediction date\n",
    "    prediction_date_df = df[(df['month'] == 4) & (df['rank'] > 3000)]\n",
    "\n",
    "    # Doing some strange manipulation to get a last_rebalance_rank column\n",
    "    last_rebalance_df['date'] = last_rebalance_df['date'] + pd.DateOffset(years=1) - pd.DateOffset(months=2)\n",
    "    last_rebalance_df = last_rebalance_df.rename(columns={'rank': 'last_rebalance_rank'})\n",
    "    last_rebalance_df = last_rebalance_df[['date', 'TICKER','COMNAM', 'last_rebalance_rank']]\n",
    "\n",
    "    merged_df = pd.merge(prediction_date_df, last_rebalance_df)\n",
    "    merged_df.drop(['month', 'day'], axis=1, inplace=True)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DT79U7F6V8hf"
   },
   "source": [
    "## <span style=\"color:blue\">Task 4</span>: Create a ProfTradingRule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3PXfFWtV8hf"
   },
   "source": [
    "This strategy should long stocks that are projected to enter the index and short stocks projected to exit the index, and use equal weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "A84G_iYcV8hf"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "class IRTradingRule():\n",
    "    # strategy: The index rebalancing strategy forms a new portfolio each month with long positions in firms projected to enter index, and short positions in firms projected to exit index.\n",
    "    # For each $1 NAV, we open $1 total of long positions AND $1 total of short positions\n",
    "    # This would be the max leverage allowed given 50% margin requirements\n",
    "    #\n",
    "    # Assume 100% of portfolio liquidated after each rebalance period and repurchased with new quantities\n",
    "    \n",
    "    # strategy-specifc columns for trades_df (variables we want to keep track of for subsequent analysis)\n",
    "    # usually the variables that led the strategy to open trade in the first place\n",
    "    strategy_specific_trades_df_columns = {'ir': pd.Series([], dtype='float')} \n",
    "    \n",
    "    # minumum number of stocks with available ir for us to actually trade\n",
    "    min_stocks_available = 5\n",
    "    \n",
    "    def __init__(self,portfolio_db):\n",
    "        self.portfolio_db = portfolio_db\n",
    "    \n",
    "    # Regardless of the strategy you are implementing, this method must return\n",
    "    # open_trades_df, close_trades_df\n",
    "    #\n",
    "    # open_trades_df is a DataFrame with all the required trades_df columns plus any custom ones for this strategy\n",
    "    #     each row is a new trade the strategy wants to open\n",
    "    #     method only populates the security_id (index) and quantity required columns, plus any custom columns. Rest remain NaN to be populated elsewhere\n",
    "    # close_trades_df is a DataFrame that is a subset of the rows of portfolio_db.trades_df\n",
    "    #     each row is an exist trade the strategy wants to close\n",
    "    #     we don't need to populate any columns in this function\n",
    "    def compute_trades(self,signal_df, date):                \n",
    "        # Since we are doing 100% turnover each period, all currently open trades should be closed\n",
    "        close_trades_df = self.portfolio_db.trades_df.loc[ self.portfolio_db.trades_df.loc[:,'close_datetime'].isna() ,: ].copy()\n",
    "        \n",
    "        # before deciding to open new positions, check that signal_df gives us a big enough set of stocks to actually do this\n",
    "        if( len(signal_df) < self.min_stocks_available ):\n",
    "            print(\"TEST REACHED\")\n",
    "            return self.empty_trades_df(), close_trades_df       \n",
    "        \n",
    "        # As our gross profitability measure, we'll use annual revenue (REVT), minus annual cost of goods sold (COGS), scaled by prior-year book value of assets (AT)        \n",
    "        # signal_df.loc[:,'gp'] = (signal_df.loc[:,'revt'] - signal_df.loc[:, 'cogs']) / (signal_df.loc[:,'lag_at'])        \n",
    "        # You shouldn't have to change anything below here if you are doing a decile strategy    \n",
    "            \n",
    "        # Find top 10% of signal column      \n",
    "        # need to make a copy because we are going to modify this and don't want to affect signal_df\n",
    "        buys_df = index_enter(signal_df)\n",
    "        buys_df = buys_df[buys_df['date'] == date]\n",
    "        # Find bottom 10% of signal column\n",
    "        # need to make a copy because we are going to modify this and don't want to affect signal_df\n",
    "        sells_df = index_exit(signal_df)\n",
    "        sells_df = sells_df[sells_df['date'] == date] \n",
    "\n",
    "        # With equal weights we can go directly to dollars per buy/sell\n",
    "        # Which is just NAV / number of positions\n",
    "        dollars_per_buy = self.portfolio_db.current_nav() / len(buys_df)\n",
    "        buys_df['quantity'] = dollars_per_buy / buys_df['prc']\n",
    "    \n",
    "        # figure out quantity per trade by splitting $ evenly\n",
    "        dollars_per_sell = -self.portfolio_db.current_nav() / len(sells_df) # negative because we are selling\n",
    "        sells_df['quantity'] = dollars_per_sell / sells_df['prc'] \n",
    "        # now make open_trades_df, keeping only security_id, quantity, and signal_col_name from the buys_df and sells_df\n",
    "        open_trades_df = self.empty_trades_df().append(\n",
    "        buys_df.loc[:,['security_id','quantity']]).append(\n",
    "        sells_df.loc[:,['security_id','quantity']]) \n",
    "        return open_trades_df, close_trades_df\n",
    "    \n",
    "    # Returns an empty trades_df\n",
    "    # Used so we know the right columns to populate when creating a trades_df else\n",
    "    def empty_trades_df(self):\n",
    "        return pd.concat([self.portfolio_db.empty_trades_df(), pd.DataFrame(self.strategy_specific_trades_df_columns)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXecovPqV8hf"
   },
   "source": [
    "### After running your code above, you should be able to run these tests sucessfully. Please run each cell without editing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIUdMFkTV8hf"
   },
   "source": [
    "#### `compute_trades` test: should output an open_trades_df with open positions having positive quantity and high gp, close_trades_df negative quantity and low gp, and an empty close_trades_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "rhGgwIUxV8hg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trent\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3338: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "<ipython-input-27-a2a19af95e85>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  last_rebalance_df['date'] = last_rebalance_df['date'] + pd.DateOffset(years=1) - pd.DateOffset(months=2)\n",
      "<ipython-input-27-a2a19af95e85>:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  last_rebalance_df['date'] = last_rebalance_df['date'] + pd.DateOffset(years=1) - pd.DateOffset(months=2)\n"
     ]
    }
   ],
   "source": [
    "%run portfolio_db.ipynb\n",
    "portfolio_db = PortfolioDB()\n",
    "portfolio_db.add_cash(100)\n",
    "\n",
    "data_processor = IRDataProcessor()\n",
    "trading_rule = IRTradingRule(portfolio_db)\n",
    "\n",
    "%run backtest_executor.ipynb\n",
    "executor = BacktestExecutor(portfolio_db)\n",
    "\n",
    "test_date = '1984-04-30'\n",
    "# test_price_df = data_processor.price_df_for_date(test_date)\n",
    "test_signal_df = data_processor.filter_and_rank(data_processor.signal_df)\n",
    "test_open_trades_df, test_close_trades_df = trading_rule.compute_trades(test_signal_df, test_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "rcPhhXtFV8hg",
    "outputId": "957ebeb4-43ee-4f90-abd1-86f344a2fe4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_open_trades_df:\n",
      "     security_id  quantity open_datetime  open_average_price close_datetime  \\\n",
      "134        10517  0.013072           NaT                 NaN            NaT   \n",
      "151        10605  0.022222           NaT                 NaN            NaT   \n",
      "162        10640  0.011396           NaT                 NaN            NaT   \n",
      "187        10779  0.022222           NaT                 NaN            NaT   \n",
      "240        11181  0.012177           NaT                 NaN            NaT   \n",
      "...          ...       ...           ...                 ...            ...   \n",
      "4854       83919  0.072780           NaT                 NaN            NaT   \n",
      "4858       83927  0.166355           NaT                 NaN            NaT   \n",
      "4863       83951  0.091933           NaT                 NaN            NaT   \n",
      "4904       84196  0.291121           NaT                 NaN            NaT   \n",
      "4916       84233  0.249532           NaT                 NaN            NaT   \n",
      "\n",
      "      close_average_price  ir  \n",
      "134                   NaN NaN  \n",
      "151                   NaN NaN  \n",
      "162                   NaN NaN  \n",
      "187                   NaN NaN  \n",
      "240                   NaN NaN  \n",
      "...                   ...  ..  \n",
      "4854                  NaN NaN  \n",
      "4858                  NaN NaN  \n",
      "4863                  NaN NaN  \n",
      "4904                  NaN NaN  \n",
      "4916                  NaN NaN  \n",
      "\n",
      "[908 rows x 7 columns]\n",
      "\n",
      "\n",
      "\n",
      "test_close_trades_df:\n",
      "Empty DataFrame\n",
      "Columns: [security_id, quantity, open_datetime, open_average_price, close_datetime, close_average_price]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print('test_open_trades_df:')\n",
    "print(test_open_trades_df)\n",
    "\n",
    "print('\\n\\n')\n",
    "print('test_close_trades_df:')\n",
    "print(test_close_trades_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VGuoyVIV8hg"
   },
   "source": [
    "## <span style=\"color:blue\">Task 5</span>: Run the Backtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtiPSiB-V8hg"
   },
   "source": [
    "If everything above was done correctly, the code in backtest.ipynb should produce a backtest for the gross profitability strategy with a few modifications.\n",
    "\n",
    "Copy the backtest.ipynb code here and modify it as follows:\n",
    "- Adjust the comments and strategy_info dictionary\n",
    "- Do not run bm_data_processor.ipynb and bm_trading_rule.ipynb, as these are no longer needed (the GPDataProcessor and IRTradingRule classes should already be defined above)\n",
    "- Replace the BM versions of data_processor and trading_rule with the GP versions. This should only be two lines of code\n",
    "\n",
    "Nothing else should change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "9Uz91ND6V8hg"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "# Imports\n",
    "from IPython.display import display, Markdown, Latex, clear_output\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "IVG4hU7kV8hg"
   },
   "outputs": [],
   "source": [
    "# # These tools should remain unchanged across strategies unless you have a good reason to change them\n",
    "%run portfolio_db.ipynb\n",
    "%run backtest_executor.ipynb # if you were live trading a strategy, this would be replace by code that submitted orders etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "busNeStIV8hg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trent\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3338: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Create the tools we'll need to do the backtest\n",
    "\n",
    "# Data processor, in charge of loading and doling out data\n",
    "data_processor = IRDataProcessor() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "xNEiPGwcV8hh"
   },
   "outputs": [],
   "source": [
    "# Portfolio database, keeps track of all the trades the backtest makes, the strategy NAV, and the current portfolio as we go through the backtest\n",
    "%run portfolio_db.ipynb\n",
    "portfolio_db = PortfolioDB()\n",
    "\n",
    "# Strategy logic, in charge of choosing trades based on current portfolio and data\n",
    "# This exact code would be used for live trading \n",
    "trading_rule = IRTradingRule(portfolio_db)\n",
    "\n",
    "# Trade executor, in charge of \"executing\" trades the strategy decides on, turning them into transactions and updating the portfolio\n",
    "trade_executor = BacktestExecutor(portfolio_db)\n",
    "\n",
    "# Info about the strategy, used for ex-post statistics and output not the actual backtest\n",
    "strategy_info = {\n",
    "    'brief descriptor': 'gp_dec_ew', \n",
    "    'plot descriptor': 'Gross Profitability Strategy, Value-Weighted',\n",
    "    'universe': 'Public US equities with accounting data',\n",
    "    'signals': 'gross profitability ratio, defined as (REV - COGS) / Prior Year Assets, measured between 120 days and 2 years of the end of the fiscal year',\n",
    "    'trading rule': 'Buy top 10% by gross profitability ratio, short bottom 10%, value-weighted',\n",
    "    'holding period': 'One month',\n",
    "    'periods per year': 12,\n",
    "    'output folder name': 'Output'\n",
    "}\n",
    "\n",
    "# Statistician, used to tabulate and plot statistics after the backtest runs\n",
    "%run backtest_statistician.ipynb\n",
    "statistican = BacktestStatistican(portfolio_db,strategy_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "d-hyMIw7V8hh",
    "outputId": "a2c75886-65bd-4780-9709-63e7663cb463"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n",
      "c:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1983-06-30: 100.0 | 0.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n",
      "c:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1983-07-29: 100.0 | 0.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n",
      "c:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1983-08-31: 100.0 | 0.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n",
      "c:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1983-09-30: 100.0 | 0.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n",
      "c:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1983-10-31: 100.0 | 0.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n",
      "c:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1983-11-30: 100.0 | 0.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n",
      "c:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1983-12-30: 100.0 | 0.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n",
      "c:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1984-01-31: 100.0 | 0.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n",
      "c:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1984-02-29: 100.0 | 0.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n",
      "c:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1984-03-30: 100.0 | 0.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n",
      "<ipython-input-27-a2a19af95e85>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  last_rebalance_df['date'] = last_rebalance_df['date'] + pd.DateOffset(years=1) - pd.DateOffset(months=2)\n",
      "<ipython-input-27-a2a19af95e85>:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  last_rebalance_df['date'] = last_rebalance_df['date'] + pd.DateOffset(years=1) - pd.DateOffset(months=2)\n",
      "c:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n",
      "c:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1984-04-30: 100.0 | 50.970887918486184'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4296: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36mna_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0muse_numexpr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36m_evaluate_numexpr\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-a15ddd7f3480>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# Update prices to reflect the new values after however much time has passed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# Need to dot his first each date because the updated prices may affect our trading rule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mportfolio_db\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_prices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-59-b01d1bd00076>\u001b[0m in \u001b[0;36mupdate_prices\u001b[1;34m(self, price_df)\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mret_tallied_dates\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m             \u001b[1;31m# multiply lagged_price by returne to get a hypothetical price\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpositions_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ret_based_price'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpositions_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'lagged_price'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpositions_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ret'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[1;31m# update quantities so that ret_based_price*old_quantity = current_price*new_quantity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(left, right)\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[0mlvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marithmetic_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m             \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mna_arithmetic_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36mna_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    148\u001b[0m             \u001b[1;31m#  will handle complex numbers incorrectly, see GH#32047\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmasked_arith_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_cmp\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\trent\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36mmasked_arith_op\u001b[1;34m(x, y, op)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m                 \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxrav\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_upcast_putmask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "# Step 3: Run actual backtest\n",
    "# Do NOT edit this cell without a very good reason\n",
    "\n",
    "# Add 100 initial cash to our portfolios\n",
    "portfolio_db.add_cash(100)\n",
    "\n",
    "# Get our list of unique dates\n",
    "udates = data_processor.unique_dates()\n",
    "\n",
    "# Main loop for the backtest\n",
    "for date in udates:\n",
    "    # dataframes for the date\n",
    "    temp_df = data_processor.signal_df_for_date(date)\n",
    "    signal_df = data_processor.filter_and_rank(data_processor.signal_df)\n",
    "    # price_df = data_processor.price_df_for_date(date)\n",
    "    # Update prices to reflect the new values after however much time has passed\n",
    "    # Need to dot his first each date because the updated prices may affect our trading rule\n",
    "    portfolio_db.update_prices(temp_df)\n",
    "    \n",
    "    if date.month == 4: \n",
    "        # Ask the trading rule what trades we should make\n",
    "        open_trades_df, close_trades_df = trading_rule.compute_trades(signal_df=signal_df, date=date)\n",
    "        # apply dates to trades\n",
    "        open_trades_df.loc[:,'open_datetime'] = date\n",
    "        close_trades_df.loc[:,'close_datetime'] = date\n",
    "\n",
    "        signal_df = data_processor.signal_df_for_date(date)\n",
    "        # execute trades\n",
    "        trade_executor.execute_opens(open_trades_df=open_trades_df, price_df=signal_df)\n",
    "        trade_executor.execute_closes(close_trades_df=close_trades_df, price_df=signal_df) \n",
    "    \n",
    "    signal_df = data_processor.signal_df_for_date(date)\n",
    "    # Record account data for today\n",
    "    portfolio_db.record_account_data(price_df=signal_df,datetime=date)\n",
    "    \n",
    "    # Do some fancy output tracking our NAV and margin requirement each day\n",
    "    # clear_output(wait=True)\n",
    "    display( np.datetime_as_string(np.datetime64(date), unit='D') + ': ' + str(portfolio_db.current_nav()) + \" | \" + str(portfolio_db.current_margin()))\n",
    "# Now that the loop is done, tell the statistican to output stats\n",
    "statistican.output_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Id5LFD6V8hh"
   },
   "source": [
    "<span>EXTRA CREDIT</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PY2BozbUV8hh",
    "outputId": "e58c3dd9-18ac-4018-e7e0-10730fd126d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIRST HALF ANNUAL RETURN: 1.45% \n",
      "SECOND HALF ANNUAL RETURN: 5.93% \n"
     ]
    }
   ],
   "source": [
    "account_history = pd.read_csv(\"Output/gp_dec_ew_202303091451/account_history.csv\")\n",
    "account_history\n",
    "\n",
    "account_history['daily return'] = account_history['nav'].pct_change(1)\n",
    "history_1, history_2 = account_history.iloc[:315,:], account_history.iloc[316:,:]\n",
    "\n",
    "history_1_avg_daily_return = history_1['daily return'].mean()\n",
    "history_2_avg_daily_return = history_2['daily return'].mean()\n",
    "\n",
    "history_1_annual_return = history_1_avg_daily_return * 12\n",
    "history_2_annual_return = history_2_avg_daily_return * 12\n",
    "\n",
    "print(\"FIRST HALF ANNUAL RETURN: {:.2%} \".format(history_1_annual_return))\n",
    "print(\"SECOND HALF ANNUAL RETURN: {:.2%} \".format(history_2_annual_return))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "08aaebccf46177101be16f6e26ae2889575a915459ea24a9bfd89d18fb6b39fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
